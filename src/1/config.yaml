hydra:
  run:
    dir: ./
  output_subdir: null

run:
  seed: 1234
  project: wandb_mclip
  id: 0   # override this with command-line argument

preprocess:
  sample_size: '16*10'   # 'full' or 'train.batch_size * N'

model:
  text_model_name: M-CLIP/XLM-Roberta-Large-Vit-B-16Plus   # 'M-CLIP/LABSE-Vit-L-14'

optimizer:
  lr: 5e-7   # originaly 5e-5
  betas: [0.9, 0.98]   # tupple not supported
  eps: 1e-6
  weight_decay: 0.2

train:
  batch_size: 16
  max_epochs: 5
  accelerator: gpu
  devices: 1

eval:
  Ks: [1, 5, 10]
